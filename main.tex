\documentclass[twocolumn]{article}
\usepackage{acro}
\usepackage[backend=biber]{biblatex}
\usepackage[inline]{enumitem}
\usepackage{amsmath}
\usepackage{cleveref}
\usepackage{pgfplots}
\usepackage{import}
\usepackage{booktabs}
\usepackage{makecell}
\usepackage{todonotes}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{pgfplots}
\usepackage{pgfplotstable}

\usepgfplotslibrary{groupplots}
\usepgfplotslibrary{colorbrewer}

% Custom commands
\definecolor{gdvGreen}{HTML}{00B000}
\definecolor{gdvOrange}{HTML}{FFAA00}
\definecolor{gdvRed}{HTML}{E9002D}

\newcommand{\skill}{{\color{gdvGreen}{$\boldsymbol{+}$}}}
\newcommand{\noskill}{{\color{gdvOrange}{$\boldsymbol{-}$}}}
\newcommand{\snoskill}{{\color{gdvRed}{$\boldsymbol{/}$}}}

\newcommand*\elide{\textup{[\,\dots]}}

% Layout
\setuptodonotes{inline}
\usepackage[font=small]{caption}

\pgfplotsset{every tick label/.append style={font=\footnotesize}}
\pgfplotsset{every axis label/.append style={font=\footnotesize}}
\pgfplotsset{every axis legend/.append style={font=\footnotesize}}



% Preabmle
\input{acronyms.tex}
\addbibresource{references.bib}

\author{
Arne Van Den Kerchove,
Juliette Meunier,
Marie de Moura, \\
Alixe Willemssens,
Hakim Si-Mohammed,
Etienne Allart, \\
Marc M. Van Hulle,
Fran√ßois Cabestaing
}

\title{Visual ERP-based Brain-Computer Interfaces in patients
with severe physical, speech and eye movement impairment: case studies}

\begin{document}

\maketitle

\section{Introduction}

Severe neurological conditions, such as severe acquired brain lesions,
neuromuscular disorders or amyotrophic lateral sclerosis can result in
\ac{sspi}.
This in turn highly alters an individual's ability to communicate and interact
with their environment, which reduces the level of activity and participation,
and overall quality of life.
\Ac{aac} technology leveraging visual \acp{bci},
which relies on the interpretation of visual stimuli by the user,
offers several advantages in this context.
Visual \acp{bci} can work with non-invasive recording technology and can use rapid
stimulation.
This makes them well-suited for real-time communication tasks.

However, severe visual impairments such as nystagmus (uncontrolled eye movements), diplopia (double
vision), ophthalmoplegia (eye paralysis) fatigability and head motion
limitations can significantly hinder the ability to use visual BCIs.
These impairments make it difficult for
\ac{bci} users to track or focus on track visual stimuli accurately, reducing their
performance with BCIs that rely on visual cues~\cite{McCane2014,FriedOken2020,Pasqualotto2015}.
Unfortunately, it is again for this group that eye tracking solutions also
perform poorly, making them more reliant on potential developments in \ac{bci}
that do not rely on eye gaze.

Eye motor impairments are presumed to reduce performance in operating visual
oddball~\cite{VanDenKerchove2024a}, since users
cannot comfortably redirect their gaze at the desired target,
i.e., perform overt \ac{vsa}.
This is usually circumvented by designing gaze-independent~
\acp{bci}~\cite{Riccio2012}.
These interfaces either avoid visual stimulation or exploit some form of
covert \ac{vsa}, where gaze and \ac{vsa} do not coincide.

Several studies with visual oddball \acp{bci} show that performance drops when not fixating the intended
target~\cite{Brunner2010, Treder2010, RonAngevin2019}, necessitating
gaze-in\-de\-pen\-dent solutions.
These studies build on the assumption that \ac{bci} users with \ac{sspgi}
would feel comfortable operating an interface in pure covert \ac{vsa} with
central fixation.
One could argue that a \ac{bci} that is only verified to work when central
fixation is maintained could also be considered gaze-dependent.
This does not account for the residual eye motor capabilities of most people
with \ac{sspi}, the (dis)comfort they experience while
performing gaze fixation and other confounding factors resulting from their eye
motility.

It is notable that studies reporting on
gaze-independent visual \ac{bci} with people with \ac{sspgi} are very few.
Results are usually different from those obtained with healthy control
participants, due to difference in capabilities, brain
response, equipment and environment.

\textcite{Lesenfants2014} tested a \ac{bci} using gaze-independent \acp{ssvep} in six
participants with \ac{lis} yet only exceeded chance level accuracy in two.
More recently, \textcite{Peters2020} performed a trial with two
participants with late-stage \ac{als} with severe visual impairment.
Their \ac{ssvep} interface was not optimized for gaze-independence, but the
system showed high accuracy, outperforming an eye tracking alternative.
It would be of interest to verify if such results can be replicated with
participants with other conditions, and with a visual oddball \acp{bci}.

\textcite{Orhan2012} and \textcite{Oken2014} tested the \ac{rsvp} speller with
individuals with \ac{lis}.

\textcite{Severens2014} evaluated the visual Hex-o-Spell~\cite{Treder2010} on 5
participants with \ac{als} and showed that this visual oddball interface optimized
for gaze-independence can outperform a tactile \ac{bci}.
While this speaks to the power of visual paradigms even in groups that are
expected to have eye motor impairment, they did not verify the gaze direction
of participants during the experiment.
It was suggested that participants were performing overtly.
Participants with \ac{als} also had a substantially lower accuracy than healthy
controls (58\% vs. 88\%).

\textcite{VanDenKerchove2024} also built towards a gaze-independent solution
using the visual Hex-o-Spell interface~\cite{VanDenKerchove2024}.
They partially accounted for the fact that \ac{bci} users with \ac{sspgi} might
not fully rely on central gaze fixation by evaluating settings independent of
central fixation.
They showed gaze-independent performance can be improved in healthy subjects by
using a suited decoding strategy that corrects for latency jitter in covert \ac{vsa} responses.
Yet, there is a strong need for verification of these results in an applied
setting with people with \ac{sspi}.

Eventually, the end goal of this research line is to develop
gaze-independent \ac{bci} for people that are fully locked-in and have no option
left other than a \ac{bci}.
However, this group is very small and it is often challenging to recruit them
into a study and perform experiments~\cite{Wolpaw2006}.
Individuals with less severe paralysis or in less progressed disease stages that struggle with
eye-tracking technology could also benefit from
solutions tailored to their specific situation.
Therefore, we aim to apply the concepts from earlier work and literature to
people with \ac{sspi} and various degrees of motor impairment in a visual oddball
\ac{bci}.
The objectives of this study are as follows:
\begin{enumerate*}
  \item Explore the capabilities and experienced comfort of individuals with
    \ac{sspgi} when operating a visual \ac{bci},
  \item evaluate the performance of a gaze-independent visual \ac{bci} for this
    group,
  \item verify if this performance can be improved with a suitable decoding
    strategy.
\end{enumerate*}


\section{Materials \& methods}
\subsection{Recruitment}
Participants were recruited across the Neuromuscular Reference center at
University Hospital Leuven (Leuven, Belgium), TRAINM Neuro Rehab Clinics
(Antwerp, Belgium), the Neurorehabilitation Unit at the Lille University
Medical Center (Lille, France), and a specialized care home (Loos,
France).\todo{Should the location be mentioned or censored for the sake of
patient anonymity, since it reveals where they live? Option A: a specialized care
home (France), Option B: Fondation Partage et Vie (Loos, France), Option C: a
specialized care home (Loos, France)}
Ethical approval for this multi-center study was obtained from the Ethics
Comission of the University Hospital Leuven (S62547).
Experiments were performed under the supervision of the treating physician.

In order to be recruited, participants must:
\begin{enumerate}
  \item be at least 18 years old and no older than 60
	years,
  \item belong to class 2 or 3 according to the \ac{bci}	user selection criteria
    presented by~\textcite{Wolpaw2006},
    \label{item:patients/inclusion/wolpaw}
  \item have limitations to the extent or comfort of their eye motor control
  	(gaze paralysis or uncontrolled gaze movements)
    \label{item:patients/inclusion/oculomotor}
  \item have given their informed consent prior to participation.
\end{enumerate}
Participants were excluded if they:
\begin{enumerate}
  \item had a diagnosis of a major medical condition, including any major
    neurological or psychiatric disorder other than those of interest based on
    inclusion criteria~\ref{item:patients/inclusion/wolpaw},
    and~\ref{item:patients/inclusion/oculomotor}\label{item:patients/exclusion/medical}
  \item had a predisposition to or a history of any kind of epileptic seizures,
    including photosensitive epilepsy,\label{item:patients/exclusion/epilepsy}
  \item had a severe loss in vision or hearing that would significantly impair
        participation in the experiment,\label{item:patients/exclusion/vision}
  \item were using specific psychoactive medications or substances that could affect the outcome.
  (neuroleptics or benzodiazepines)
  \label{item:patients/exclusion/cognitive}
  \item were unable to understand the experiment instructions and cooperate,
  \item had any other limitations preventing them from performing the given task.
\end{enumerate}

In total, 11 individuals were contacted. Of these, one person with
\ac{ms} was excluded based on criterion~\ref{item:patients/exclusion/vision}.
One person recovering from \ac{tbi} was excluded based on both~\ref{item:patients/exclusion/epilepsy}
and~\ref{item:patients/exclusion/cognitive}, and one person recovering from
stroke based on~\ref{item:patients/exclusion/medical}.
One further person recovering from a stroke was excluded due to technical
difficulties during the experimental session.

Ultimately, 7 participants were retained.
Of these, one participant was diagnosed with bulbar-onset \ac{als}, three with
\ac{fa} an three were recovering from \ac{lis} due to stroke.
Table~\ref{tab:patients/patients} lists the included participants and their
diagnoses.
\begin{table*}[t]
  \centering
  \footnotesize
  \input{patients_table.tex}
  \caption[Included participants with their diagnosis and
    capabilities.]{Included participants with their diagnosis and
    capabilities.
    Trach.: underwent a tracheostomy, W: classification according
    to~\textcite{Wolpaw2006}, KB: classification according
    to~\textcite{Kuebler2008}.
  }
  \label{tab:patients/patients}
\end{table*}
\todo{include years since diagnosis}

\subsection{Visual skills and eye tracking and eye motor examination}

Vision was assessed using a LogMAR chart~\cite{Bailey1976}.
Self-reported eye motor and visual abnormalities were recorded according to the
relevant visual \ac{bci} skills presented by~\textcite{FriedOken2020}.
These include visual acuity, visual fixation, eyelid function, ocular motility,
binocular vision, and field of vision.
Additionally, participants and their caregivers were asked about eye tremors
(nystagmus or other) and other involuntary eye movements.
\todo{replace with neuro-ophtalmolocigal examination}

%As an objective metric, we implemented and performed the automated NeuroEye eye movement
%test proposed by~\textcite{Hassan2022} using calibration-free eye tracking to
%check if it revealed any further eye motor abnormalities.
%This was not the case.

\begin{table*}[t]
  \footnotesize
  \centering
  \input{patients_table_eye.tex}
  \caption[Visual skills of the included participants.]{%
    Self-reported visual skills as defined by \textcite{FriedOken2020} of the included participants.
  \skill\ skilled, \noskill\ impaired, \snoskill\ severely impaired.
  Visual acuity was assessed using the logMAR scale (lower is better).}
  \label{tab:patients/eye}
\end{table*}

Finally, we also recorded gaze position throughout the experimental session to
register the participant's gaze relative to the stimulated \ac{bci} targets.




\subsection{\Acs{bci} stimulation}

The \ac{bci} stimulation procedure was based on the
Hex-o-Spell~\cite{Treder2010} implementation presented
by~\textcite{VanDenKerchove2024}.
Similar to this study, the task consists of counting the flashes of a cued
target among 6 round, flashing targets laid out in a hexagonal pattern in the
field of view of the user as displayed
in~\cref{fig:methods/stimulation/stimulation}.
We refer to \textcite{VanDenKerchove2024} for further implementation details of
the stimulation procedure.
\begin{figure*}[t]
  \centering
  \begin{subfigure}[b]{.41\textwidth}
    \includegraphics[width=\textwidth]{figures/PD01b-obfuscated.jpg}
    \caption{A participant seated in a wheelchair in front of the stimulation laptop with EEG
    cap.}
  \end{subfigure}\hfill%
  \begin{minipage}[b]{.54\textwidth}
    \begin{subfigure}[b]{.45\linewidth}
      \includegraphics[width=\textwidth]{figures/stim_overt.pdf}
      \caption{Stimulation interface with 6 targets and fixation crosshair
      positioned for \emph{overt} \ac{vsa}.}
    \end{subfigure}\hfill%
    \begin{subfigure}[b]{.45\linewidth}
      \includegraphics[width=\textwidth]{figures/stim_covert.pdf}
      \caption{In \emph{covert} \ac{vsa}, the fixation crosshair is placed in the
      center of the screen.}
    \end{subfigure}
    \smallskip

     \begin{subfigure}[b]{.45\linewidth}
      \includegraphics[width=\textwidth]{figures/stim_free.pdf}
       \caption{In \emph{free} \ac{vsa}, no fixation crosshair is displayed.}
    \end{subfigure}\hfill%
     \begin{subfigure}[b]{.45\linewidth}
      \includegraphics[width=\textwidth]{figures/stim_intense.pdf}
      \caption{Targets are intesified by enlarging them for 100 ms.}
    \end{subfigure}
  \end{minipage}

  \caption{Stimulation and recording setup for the oddball \ac{bci} experiment
  with different \ac{vsa} conditions}
  \label{fig:methods/stimulation/stimulation}
\end{figure*}

Three different \ac{vsa} settings were explored.
In the overt \ac{vsa} setting, the participant was instructed to fixate on the cued target or
try to the maximum extent of their visual skill, even if experiencing slight
discomfort.
In the covert \ac{vsa} setting, the participant was instructed to fixate on the center of the
screen, to the extent of their ability.
An additional \emph{free \ac{vsa}} setting was introduced.
Here, the participant was instructed to perform the task as they deemed most
comfortable.
This allowed us to investigate the user's natural way of operating the \ac{bci}
given their individual set of visual skills.
If the participant was not fully paralyzed, they were instructed not to move their head.
The cued \emph{split attention} setting proposed
by~\textcite{VanDenKerchove2024} was not studied here, as we were interested
in natural \ac{vsa} operation settings for gaze-impaired individuals.

To make the interface suitable for use by individuals with
\ac{sspi}~\cite{FriedOken2020}, the
number of blocks was decreased to 6 per \ac{vsa} setting.
In order to decrease task difficulty, \ac{isi} was increased to 200 with added random jitter uniformly distributed
between -50 ms and 50 ms.
The experiment also started with a training block in each condition, where the
participant was instructed with feedback on their performance to ensure they
understood and were able to perform the task.


\subsection{Data collection \& preprocessing}

During the recording session, participants were positioned in their wheelchair in front of a table.
Stimuli were presented on an Acer Predator Helios laptop with an 18" screen (Acer,
Inc., Taiwan) placed at a 60 cm distance.
A Cedrus StimTracker (Cedrus Corp., CA, USA) ensured synchronization of stimuli with the
recorded \ac{eeg}.
Eye tracking was performed throughout using the Tobii X2-30 Compact (Tobii
Technology AB, Sweden) portable eye tracker placed at the bottom of the laptop screen.

\Ac{eeg} was recorded at 1000 Hz using the Neuroscan Neuvo portable amplifier (Compumedics Neuroscan,
Australia) connected to a second laptop for registration.
The \ac{eeg} headset used 18 active AgCl electrodes (EASYCAP GmbH, Germany) placed on a cap
according to the international 10-20 layout.
Using electrolyte gel, electrode impedances were reduced below 10 k$\Omega$.
Additionally, the \ac{eog} was recorded.

The \ac{eeg} was band-pass filtered between 0.5 and 16 Hz.
Bad channels were rejected using the RANSAC algorithm~\cite{Fischler1981}
and visual inspection.
Next, the \ac{eeg} was re-referenced to the average of mastoid electrodes TP9
and TP10, and \ac{ica} was performed to reject artifactual components based on
correlation with the \ac{eog} or by visual inspection.
Epochs were cut from -0.1 to 0.9 s relative to stimulus onset, and no baseline
correction was performed.

Eye tracking data was cleaned by fusing left and right eye screen-based gaze
coordinates into one channel for the horizontal and one for vertical gaze position.
If both were present for a given sample, the fused channel was the mean of both
values.
If at a given sample either the left or the right eye was not detected for a
given channel, the value of the other one was adopted.
If both were missing, the gaze position remained unset at that time point, and no
interpolation was performed.

\subsection{\Acs{bci} decoding}

We evaluated the recorded data using the \ac{wcble}~\cite{VanDenKerchove2024}
and \ac{tlda}~\cite{Sosulski2022}
classifiers, as well as the Riemannian approach XDAWNCov+TS+LDA~\cite{Cecotti2017}.
For \ac{wcble}, a region of interest from 0 ms to 800 ms relative to stimulus
onset was used while the epoch was cropped to -100 ms to 900 ms. For the other
decoders, the epoch was cropped between 0 ms and 800 ms, which resulted in maximal
performance.
Decoding scores were obtained using 6-fold cross-validation where folds corresponded to
stimulation blocks.

\section{Results}



\subsection{Visual skill and eye tracking analysis}
\label{sec:patients/outcomes/gaze}

Table~\ref{tab:patients/eye} details the eye motor impairments and vision of
the included participants.
All participants reported some degree of fatigue or discomfort when fixating.
Participant PA1 had the mildest impairment, only reporting fatigue when fixating
for prolonged times.
The \ac{fa} participants were mostly affected by eye tremors and impaired pursuit.
PB2 suffered from especially severe horizontal oscillating involuntary eye
movements.
Eye motor function of participants PC2, PC3, and PC4 was most severely affected.
Participant PC2 was only able to look up and down and had a deviation in the
left eye causing diplopia, but this was corrected by a prism glass.
Participant PC3 only retained partial motility of the right eye, while the left eye was permanently closed.
Participant PC4 had one deviated eye with a corneal abscess affecting the motility
and vision in the right eye, and reducing motility in the left.


Given these information, we aimed to shed more light on the actual capabilities of individuals
with \ac{sspgi} regarding performing overt \ac{vsa} and central gaze
fixation, as well as to investigate how relevant these two settings are when the
gaze is not cued.
\Cref{fig:patients/gaze} maps gaze position relative to the stimuli
across conditions.
These results should be interpreted with care, as the eye tracker partially
relies on functioning eye motility.
The participant's position relative to the eye tracker might have shifted
throughout the experimental session despite our best efforts, e.g., because they
needed aspiration of their tracheostomy.
\begin{figure*}[t]
  \resizebox{\linewidth}{!}{%
    \import{figures}{fig_gaze.pgf}%
  }%
  \caption[Distribution of the recorded gaze position.]{%
    Distribution of the recorded gaze position during the experimental session in the three \ac{vsa}
    conditions.
    Crosshairs represent stimulus positions, with the orange ones cued during
    the given condition.
    Subjects PB2 and PC4 preferred covert \ac{bci} operation, with PB2 resting gaze
    near the middle of the screen, and PC4 near the bottom.
  }%
  \label{fig:patients/gaze}
\end{figure*}

PA1 had relatively intact gaze control and was able to correctly perform the
cued overt and covert settings.
When gaze was uncued, he fixated on the cued target.
This was also mostly the case for PB1, although eye tracking revealed that he
chose not to perform central gaze fixation when cued in at least one of the
stimulation blocks. We were unable to record his gaze near the bottom-left
stimulus position, either due to eye tracker failure or because the participant
was not comfortable fixating on this position.
Eye tracker calibration did not succeed for subject PB4, but given
transformation of gaze positions to the stimulus space, they were assumed to
be overtly performing the free task.

PB2 was able to perform overt \ac{vsa} and central fixation to some extent,
yet eye tracking shows a larger spread in gaze position compared to
PA1 and PB1.
In the free \ac{vsa} condition, however, she preferred to attend
stimuli covertly when the gaze was uncued.
This was confirmed by the participant.

The overt and central gaze fixation settings were also not properly adapted to
participant PC4.
In the free \ac{vsa} condition, eye tracker results show that his gaze was usually near the
bottom two targets, indicating some degree of covert or split \ac{vsa}.

Technical difficulties were encountered while registering gaze position with the Tobii X2-30
Compact for participants PC2 and PC3, since they both had one eye that was
occluded respectively by the prism glass and the eyelid.
Both participants reported they could not fixate on some of the
stimuli.

\subsection{\Acs{bci} decoding performance}

\Cref{fig:patients/decode} shows cross-validated single-trial target selection
accuracy for the evaluated \ac{vsa} settings for the different decoders.
\todo{replace by accuracy}

In the overt \ac{vsa} setting, the evaluated decoders performed similarly on average
(\ac{wcble} 75.58\%, XDAWNCov+TS+LDA 74.24\%, \ac{tlda} 75.99\%).
In the covert \ac{vsa} setting with cued central gaze fixation, performance deteriorated,
but \ac{wcble} significantly improved performance over the base classifier
\ac{tlda} in this condition
(\ac{wcble} 62.49\%, XDAWNCov+TS+LDA 59.42\%, \ac{tlda} 59.05\%).
Decoding performance for this task was at chance level for participants PB4 and
PC3.
\todo{replace values by accuracy}

However, \ac{wcble} did not improve \ac{tlda} performance in the free \ac{vsa} setting, but
XDAWNCov+TS+LDA performance was slightly lower here (though not
significantly).
(\ac{wcble} 74.15\%, XDAWNCov+TS+LDA 71.88\%, \ac{tlda} 74.27\%).
More interestingly, we noticed that performances of the decoders in free
\ac{vsa} were close to those in the overt \ac{vsa}.
A substantial decrease in performance from the overt setting to the free
setting was observed for subjects PC3
(\ac{wcble}: 70.31>62.14 \%, XDAWNCov+TS+LDA: 65.78>62.18 \%, \ac{tlda}:
70.49>63.76 \%)
and PC4
(\ac{wcble}: 65.56>55.71 \%, XDAWNCov+TS+LDA: 62.02>54.24 \%, \ac{tlda}:
66.12>57.08 \%).
For PB2, who also relied on covert \ac{vsa} during the uncued free \ac{vsa}
according to gaze tracking setting, the decrease in performance was also
present, but not as substantial
(\ac{wcble}: 82.76>78.88 \%, XDAWNCov+TS+LDA: 80.74>77.99 \%, \ac{tlda}:
83.21>78.84 \%).
\begin{figure*}[t]
   \input{figures/decode.tikz.tex}
  \caption[%
    Decoding performance in different \acs{vsa} settings.
  ]{%
    Decoding performance in different \ac{vsa} settings reported as
    single-trial target selection accuracy (\%).
    Free \ac{vsa} is generally on par with performance in the overt \ac{vsa}
    setting.
    Performance in the covert \ac{vsa} setting with central gaze fixation is lower, but can
    be improved with the \ac{wcble} decoder.
    95\% confidence intervals were calculated using 10,000 bootstrapping
    repetitions.
  }
  \label{fig:patients/decode}
\end{figure*}

\subsection{Cross-condition calibration}
\label{sec:patients/outcomes/cross}
\todo{replace fig with accuracy, check if description fits}

As an alternative approach to selecting the most suitable decoder, we used
\ac{tlda} as the base decoder and verified whether performance could be improved
if \ac{bci} users with gaze impairment performed the calibration session relying
maximally on their residual gaze control.

\Cref{fig:patients/cross} shows that, on average, covert \ac{vsa} decoding
improved when training with overt \ac{vsa}.
This was especially true for participants PA1, PB2, and PC3.
Note that, according to eye tracking data, participants PB1, PB4, and PC4 did not
always perform cued central gaze fixation in the covert \ac{vsa} setting,
which might have affected the results.
\begin{figure*}[t]
  \input{figures/fig_cross.pgf}
  \caption[Cross-setting calibration and decoding performance.]{
    Decoding performance when calibrating the \ac{tlda} decoder in a given \ac{vsa}
    setting, and evaluating it in another, reported as
    single-trial \ac{rocauc}.
    For participant PA1, free \ac{vsa} performance improved when
    calibrated with overt gaze fixation.
    For participants PA1, PB2, and PC3, performance in the covert \ac{vsa} setting with central gaze fixation
    improved when calibrating with overt gaze fixation.
  }
  \label{fig:patients/cross}
\end{figure*}

\section{Discussion}

\todo{Add a short section to emphasize on the main results (head of the
different parts of the discussion)}

\subsection{Gaze-independent operation \& decoding}
Due to the heterogeneous nature of the participants' conditions, it is difficult to
draw general conclusions.
This study should therefore be seen as a collection of case studies,
highlighting different obstacles encountered in developing gaze-independent
visual oddball \acp{bci} for individuals with \ac{sspgi}.
Nevertheless, we would like to highlight some aspects that might be
of interest for the further development of this class of \acp{bci}.

True gaze-independent visual \acp{bci} should not rely on gaze fixation.
Hence, our analysis centers around the free \ac{vsa} condition.
Eye tracking results presented in \cref{sec:patients/outcomes/gaze}\todo{fix
ref}
confirm our assumption that voluntary covert \ac{vsa} can
occur in individuals with \ac{sspgi}.
We also confirmed part of the results from~\textcite{VanDenKerchove2024}
presented in \cref{sec:covert-align}, which state that decoding of covert \ac{vsa} with central gaze
fixation can be improved by accounting for latency jitter. We showed that this
also holds for individuals with \ac{sspgi}.

Contrary to our assumptions, we have shown that this does not
necessarily improve covert \ac{vsa} when gaze fixation is not cued.
One possible explanation is that actively performing central gaze fixation
increases task load.
This, in turn, can reduce overall performance, even though the participant might
have otherwise performed covert \ac{vsa}, but would not be occupied with
maintaining strict central gaze fixation.
This extra task demand is not present in the free \ac{vsa} condition, so
there is less performance to be gained.
Furthermore, cued central gaze fixation combined with counting flashing stimuli
in the visual periphery is an explicit example of a dual task.
Dual tasks have been shown to increase P3 latency
jitter~\cite{Polich2007,Arico2014, VanDenKerchove2024},
which is what \ac{wcble} accounts for.
Hence, increased P3 jitter might be more related to maintaining central gaze fixation
than to the actual covert \ac{vsa} aspect.

The seemingly stable performance across overt and free \ac{vsa} could be
misinterpreted as an indication that the Hex-o-Spell \ac{bci} already works
well for individuals with \ac{sspgi}, and no optimization is
needed.
However, we assume that overt \ac{vsa} performance was also decreased in some
subjects or for some blocks if the participant was not able to comfortably
perform the task.
Nevertheless, the large difference between the free \ac{vsa} setting and the
covert \ac{vsa} setting
with central gaze fixation is food for thought about the applicability of
solutions developed with central fixation in mind.

Individuals with all but the most severe gaze impairments will likely retain
some degree of gaze direction in visual \ac{bci} operation, which can
drastically boost performance.
Subject PB2 exemplifies this: his free \ac{vsa} performance is on par with his
overt \ac{vsa} performance, although eye tracking showed that he relied mostly
on overt \ac{vsa} when cued to do so, and mostly on covert \ac{vsa} when
gaze was uncued.
This is also supported by our results on cross-condition calibration presented
in \cref{sec:patients/outcomes/cross}, which show that leveraging residual
eye motor control to fixate targets during the calibration phase can improve
performance in some settings.
This is likely due to the increased P3 component amplitude in overt \ac{vsa},
which improves the discriminative power of a classifier trained on this data.
Cueing this overt gaze fixation only during the calibration phase leaves the user
free to operate in the manner that is most comfortable for them in the
operation phase.
Early VEPs in the training data could also contribute in those cases where the participant was not
able to perform covert \ac{vsa} with central gaze fixation.

\subsection{Clinical implications}
The population of individuals with \ac{sspgi} is sparse, yet is regularly
confronted with major challenges.
As opposed to individuals in a vegetative or severe minimally conscious state,
they demonstrably have the intent and capability to communicate their thoughts
and desires to their clinicians, caregivers and network.
These capabilities and, however, are severely limited by their condition,
reducing the effectiveness and efficiency of communication.
Hence, finding a way to fill in this gap is a major issue in the care of
individuals with \ac{sspgi}.

Our work shows that some patients might benefit from visual \acp{bci}
for home use or in the clinical setting.
While the proposed communication protocol is a proof of concept with a limited degree
of freedom, it is a step towards applications like textual communication and
environment or home automation control that inherits the relatively high
information transfer rate of visual \acp{bci}.

Furthermore, our experimentation revealed that the required technology and its
potential applications were generally well received by the participants and their
environment.
While the necessary visual attention task can be taxing if performed for longer
periods of time, participants indicated that this was outweighed by the
potential to communicate in a more automated and autonomous way compared to
their current \ac{aac} solutions, which often required the help of a trained caregiver of a trained
caregiver.

\subsection{Limitations}

Despite results that prompt interesting reflections on gaze-independent \ac{bci}
approaches, there are some limitations to the presented results that should be
addressed in ongoing and future work.

First and foremost, this study works with a limited sample size, which
does not represent the full spectrum of individuals with \ac{sspi} and
\ac{sspgi}, and their specific symptoms and skills.
Individuals with \ac{fa} met the inclusion criteria, but they are usually not
considered one of the typical interest groups for \ac{bci} communication assistive
technology, partly due to the rarity of the disease and partly due to its
progression.
It would be most interesting to verify these results with individuals with
\ac{lis} and no eye movement capability at all.

Another limiting factor is the difficulty experienced in correctly interpreting eye
tracker results in studies with individuals with gaze impairments.
If eye tracking is possible at all, it is not guaranteed that the user is able
to successfully perform the calibration procedure.
Further experiments should be carried out with a stationary eye tracker with
more advanced capabilities, although systems using a head fixator or headrest
should be avoided.
This is not practical when working with
wheelchair-bound individuals who might have undergone a tracheostomy and may
suffer from spasticity.

In this study, user comfort in the different conditions was not objectively
measured.
Instead, it was assumed that participants operated most comfortably in the free
\ac{vsa} condition.
Even though participants reported that they could comfortably operate the
system, this must be confirmed with more quantitative assesments.
To properly contextualize performance results, they should be coupled with
metrics evaluating the full scope of the user's requirements, with measures of
usability, comfort and perceived effort, like the NASA Task Load
Index~\cite{Hart2006} and other metrics proposed in the user-centered design
framework for \acp{bci}~\cite{Kuebler2014}.
Performance might, after all, be traded off for user comfort.
The perception of this type of \ac{bci} by the user might also be influenced by
performing the experiment in an on-line manner, providing immediate feedback
after selection.
%Eye motor disability could also have been assessed more
%objectively~\cite{FriedOken2020}, using, e.g.,
%the Revised Coma Recovery Scale~\cite{Giacino2004} or the NSUCO
%oculomotor exam~\cite{Maples1992}.

Finally, the stimulation procedure parameters
from~\textcite{VanDenKerchove2024} were adapted to make the counting task
accessible to the \ac{bci} users with \ac{sspgi}.
However, the number of repetitions and the \ac{isi} were not optimized to achieve
maximal \ac{itr}.
An interface that aims to maximize \ac{itr} could necessitate more or faster
gaze redirections, which might result in different conclusions regarding the
comfort and the impact of visual skill.

\section{Conclusion}
\todo{Add conclusion, base on summarizing and conclusions in thesis}
\printbibliography

\end{document}
